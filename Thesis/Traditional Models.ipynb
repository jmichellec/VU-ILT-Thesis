{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668f7cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6739615",
    "outputId": "a1e957ec-a102-4564-c669-da776c27ace3"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import pprint\n",
    "import pyLDAvis.gensim_models\n",
    "import spacy\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_data(prep_tokenized, nlp):\n",
    "    nlp = spacy.load('nl_core_news_sm')\n",
    "    lemmatized = []\n",
    "    for text in prep_tokenized:\n",
    "        doc = nlp(' '.join(text))\n",
    "        lemmatized.append([token.lemma_ for token in doc])\n",
    "    return lemmatized\n",
    "\n",
    "def tokenize_clean(texts):\n",
    "    for text in texts:\n",
    "        yield(simple_preprocess(str(text), deacc=True, min_len=1, max_len=100))  # removes punctuation, lowercases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6178cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/complete-clean-preprocessed-data-2010-2020.tsv', sep='\\t')\n",
    "# tokenized = tokenize_clean(df['preprocessed_hlead'].to_list())\n",
    "# lemmatized_tokenized = lemmatize_data(tokenized, nlp)\n",
    "# df['lemmatized_tokenized'] = lemmatized_tokenized\n",
    "# df.to_csv('data/complete-clean-preprocessed-data-2010-2020.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f089cd",
   "metadata": {
    "id": "9d88245c"
   },
   "outputs": [],
   "source": [
    "def doc_term_matrix(data):\n",
    "    lemmatized_tokenized = data.tolist()\n",
    "    dictionary = Dictionary(lemmatized_tokenized)\n",
    "    dictionary.filter_extremes(no_below=1, no_above=0.9)\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [dictionary.doc2bow(text) for text in lemmatized_tokenized]\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    print(\"Finished doc_term_matrix\")\n",
    "    return corpus_tfidf, corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, data, dictionary, corpus):\n",
    "    coherence_model = CoherenceModel(model=model, texts=data, dictionary=dictionary, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "#     perplexity = model.log_perplexity(corpus)\n",
    "    return coherence#, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac31eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(data, model, dictionary, corpus, name):\n",
    "    \n",
    "    # Change depending on models one wants to check\n",
    "    models = [model(corpus, num_topics=5, id2word = dictionary, passes=20, random_state=123),\n",
    "             model(corpus, num_topics=10, id2word = dictionary, passes=20, random_state=123),\n",
    "             model(corpus, num_topics=20, id2word = dictionary, passes=20, random_state=123),\n",
    "             model(corpus, num_topics=40, id2word = dictionary, passes=20, random_state=123),\n",
    "             ]\n",
    "    coherences = []\n",
    "#     perplexities = []\n",
    "    num = 0\n",
    "    for model in models:\n",
    "        coherence = evaluation(model, data, dictionary, corpus)\n",
    "        coherences.append(coherence)\n",
    "#         perplexities.append(perplexity)\n",
    "        print(\"Finished evaluating model \" + str(num))\n",
    "        path = 'models/' + name + '_' + str(num) + '.pkl'\n",
    "        pickle.dump(model, open(path, 'wb'))\n",
    "        num += 1\n",
    "    return coherences, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb20741",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cc5f9ae",
    "outputId": "ea75f14b-9d60-40c4-9ec5-d17b64da3182"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/complete-clean-preprocessed-data-2010-2020.tsv', sep='\\t', converters={'lemmatized_tokenized': literal_eval})\n",
    "data = df['lemmatized_tokenized']\n",
    "corpus_tfidf, corpus, dictionary = doc_term_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tune the number of topics using coherence\n",
    "coherences_lda, lda_models = hyperparameter_tuning(data, LdaModel, dictionary, corpus, 'lda_model')\n",
    "# Get index of highest coherence value, can also be changed to perplexity\n",
    "best_model_index_lda = np.argmax(coherences_lda)\n",
    "lda_model = lda_models[best_model_index_lda]\n",
    "# pickle.dump(lda_model, open('models/lda_model.pkl', 'wb'))\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b9430",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "0K0gBl9CNhdl",
    "outputId": "5e83633b-16a9-44a1-eea4-9c811cad0bf6"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tune the number of topics using coherence\n",
    "coherences_nmf, nmf_models = hyperparameter_tuning(data, Nmf, dictionary, corpus, 'nmf_model')\n",
    "# Get index of highest coherence value, can also be changed to perplexity\n",
    "best_model_index_nmf = np.argmax(coherences_nmf)\n",
    "nmf_model = nmf_models[best_model_index_nmf]\n",
    "# pickle.dump(nmf_model, open('models/nmf_model.pkl', 'wb'))\n",
    "nmf_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39772494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tune the number of topics using coherence\n",
    "coherences_lda_tfidf, lda_models_tfidf = hyperparameter_tuning(data, LdaModel, dictionary, corpus_tfidf, 'lda_model_tfidf')\n",
    "# Get index of highest coherence value, can also be changed to perplexity\n",
    "best_model_index_lda_tfidf = np.argmax(coherences_lda_tfidf)\n",
    "lda_model_tfidf = lda_models_tfidf[best_model_index_lda_tfidf]\n",
    "# pickle.dump(lda_model_tfidf, open('models/lda_model_tfidf.pkl', 'wb'))\n",
    "lda_model_tfidf.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tune the number of topics using coherence\n",
    "coherences_nmf_tfidf, nmf_models_tfidf = hyperparameter_tuning(data, Nmf, dictionary, corpus_tfidf, 'nmf_model_tfidf')\n",
    "# Get index of highest coherence value, can also be changed to perplexity\n",
    "best_model_index_nmf_tfidf = np.argmax(coherences_nmf_tfidf)\n",
    "nmf_model_tfidf = nmf_models_tfidf[best_model_index_nmf_tfidf]\n",
    "# pickle.dump(nmf_model_tfidf, open('models/nmf_model_tfidf.pkl', 'wb'))\n",
    "nmf_model_tfidf.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bad922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcc97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "topics = lda_model_tfidf.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in lemmatized_tokenized for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520940d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(lda_model[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(lda_model, corpus, df['preprocessed_hlead'])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 10]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CODE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
