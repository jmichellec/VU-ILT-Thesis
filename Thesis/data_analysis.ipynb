{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_files():\n",
    "    \"\"\"\n",
    "    Concatenates files of data of 100 instances together into 1 dataframe and saves it to a tsv\n",
    "    \"\"\"\n",
    "    cwd = os.path.abspath('') \n",
    "    folders = os.listdir(path+'bijlagen') \n",
    "\n",
    "    dfs = []\n",
    "    for folder in folders:\n",
    "        file = os.listdir(path+'/bijlagen/'+folder) \n",
    "        df = pd.read_excel(path+'/bijlagen/'+folder+'/'+file[0], engine='openpyxl') \n",
    "        num += len(df)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df.to_csv('data/data-2010-2020.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_clean_data(df):\n",
    "    \n",
    "    # Remove irrelevant and duplicate columns\n",
    "    df_no_irr_cols = df.drop(['Publicatie.1', 'Publicatietype.1', 'Sectie', 'Lengte.1', 'Cite', 'Bedrijf', 'Agg-copyright', 'Pub-copyright', 'Titel.1', 'Weergeven', 'Ticker'], axis=1)\n",
    "\n",
    "    # Remove rows without text \n",
    "    df_not_na = df_no_irr_cols[~df_no_irr_cols['Hlead'].isna()]\n",
    "    print('# Removed empty: ', len(df)-len(df_not_na))\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_no_dups = df_not_na.drop_duplicates()\n",
    "    \n",
    "    print('# Removed duplicates after removal empty: ', len(df_not_na)-len(df_no_dups))\n",
    "    return df_no_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(df):\n",
    "    # Remove punctuation\n",
    "    df['Jaar'] = df['Datum'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    # Retrieve years from various date formats\n",
    "    df['Jaar'] = df['Jaar'].apply(lambda x: x.rsplit(' ', 1)[0] if len(x.split()) >= 4 else x)\n",
    "    df['Jaar'] = df['Jaar'].apply(lambda x: x.split()[2] if len(x.split()) > 2 else x.split()[1])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_stats(df, path):\n",
    "    print(df.isna().mean().round(4) * 100)\n",
    "    \n",
    "    top_auteurs = df['Auteur'].value_counts().head(10)\n",
    "    top_publicaties = df['Publicatie'].value_counts().head(10)\n",
    "\n",
    "    jaar = Counter(df['Jaar'])\n",
    "    top_jaar = pd.Series(dict(sorted(jaar.items())), name='Jaar')\n",
    "\n",
    "    print(top_auteurs)     \n",
    "    print(top_publicaties)  \n",
    "    print(top_jaar)\n",
    "    \n",
    "    plt.figure()\n",
    "    ta = top_auteurs.plot(kind='bar')\n",
    "    ta.axhline(np.array(top_auteurs.values).mean(), color='r', linestyle='--', lw=1, label='mean count')\n",
    "    plt.xlabel('authors')\n",
    "    plt.ylabel('number of articles')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(path + 'top-auteurs', bbox_inches = 'tight')\n",
    "    \n",
    "    plt.figure()\n",
    "    tp = top_publicaties.plot(kind='bar')\n",
    "    tp.axhline(np.array(top_publicaties.values).mean(), color='r', linestyle='--', lw=1, label='mean count')\n",
    "    plt.xlabel('publications')\n",
    "    plt.ylabel('number of articles')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(path + 'top-publicaties', bbox_inches = 'tight')\n",
    "    \n",
    "    plt.figure()\n",
    "    tj = top_jaar.plot(kind='bar')\n",
    "    tj.axhline(np.array(top_jaar.values).mean(), color='r', linestyle='--', lw=1, label='mean count')\n",
    "    plt.xlabel('years')\n",
    "    plt.ylabel('number of articles')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(path + 'top-jaar', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_length_stats(df_col, path):    \n",
    "    # Get list of word lengths of data\n",
    "    sv = []\n",
    "    reg = []\n",
    "    for i in df_col:\n",
    "        if 'SAMENVATTING' in ' '.join(i.split()[:3]):\n",
    "            sv.append(len(i.split()))\n",
    "        else:\n",
    "            reg.append(len(i.split()))\n",
    "            \n",
    "    sv_avg = sum(sv)/len(sv)\n",
    "    reg_avg = sum(reg)/len(reg)\n",
    "    \n",
    "    print(\"Number of samenvattingen: \", len(sv))\n",
    "    print(\"Number of regular texts: \", len(reg))\n",
    "    print(\"Avg word count samenvattingen: \", sv_avg)\n",
    "    print(\"Avg word count regular texts: \",reg_avg)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(reg, bins=50, alpha=0.3, label='regular texts')\n",
    "    plt.hist(sv, bins=50, alpha=1, label='samenvatting')\n",
    "    plt.axvline(np.array(reg).mean(), color='r', linestyle='dashed', linewidth=1, label='mean regular texts')\n",
    "    plt.axvline(np.array(sv).mean(), color='k', linestyle='dashed', linewidth=1, label='mean samenvatting')\n",
    "    \n",
    "    plt.xlabel(\"word count\")\n",
    "    plt.ylabel(\"number of articles\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.savefig(path + 'wc-sv-rt-ratio.png', bbox_inches = 'tight')\n",
    "    print('Figure saved in ' + path + 'wc-sv-rt-ratio.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_samenvattingen(base_df):\n",
    "    base_df_regular = base_df[base_df['Tekstsoort'] == 'regular']\n",
    "    return base_df_regular.drop(['Tekstsoort'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate_files()\n",
    "df = pd.read_csv('data/data-2010-2020.tsv', sep='\\t')\n",
    "\n",
    "print('Length original data: ', len(df))\n",
    "print('')\n",
    "\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Data cleaning\n",
    "print('Data cleaning:')\n",
    "os.makedirs('plots/base_clean', exist_ok=True)\n",
    "\n",
    "bc_path = 'plots/base_clean/'\n",
    "base_df = base_clean_data(df)\n",
    "base_df = extract_year(base_df)    \n",
    "\n",
    "# Statistics base clean\n",
    "general_stats(base_df, bc_path)\n",
    "text_length_stats(base_df['Hlead'], bc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove summaries\n",
    "base_df['Tekstsoort'] = base_df.Hlead.apply(lambda x: 'samenvatting' if 'SAMENVATTING' in ' '.join(x.split()[:3]) else 'regular')\n",
    "regular_base_df = remove_samenvattingen(base_df)\n",
    "print(\"Stats after removing samenvattingen:\")\n",
    "print(regular_base_df.isna().mean().round(4) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_author(text):\n",
    "    text = text.lower()\n",
    "    if text[0] != ';':\n",
    "        text = text.split(\";\", 1)[0]\n",
    "    else:\n",
    "        text = ' '.join(text.split(\";\", 1)[1:])\n",
    "    if text == 'een':\n",
    "        text = 'door een verslaggever'\n",
    "    text = text.split(\"/\", 1)[0]\n",
    "    text = text.split(\"e-mail\", 1)[0]\n",
    "    text = re.sub('door', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"[()]\", '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub('|', '', text)\n",
    "    text = ' '.join([x for x in text.split() if \"@\" not in x])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_unique_authors(df):\n",
    "    authors = []\n",
    "    for i in set(df['Auteur'].values):\n",
    "        if isinstance(i, str): \n",
    "            i = clean_author(i)\n",
    "            if len(i) > 0:\n",
    "                authors.append(i)\n",
    "    return list(set(authors))\n",
    "\n",
    "def find_author(text, author, regex):\n",
    "    # if author col is empty\n",
    "    if pd.isnull(author):\n",
    "        if re.match(regex, text, flags=re.IGNORECASE):\n",
    "            new_author = re.search(regex, text, flags=re.IGNORECASE).group(0)\n",
    "            author = clean_author(new_author)\n",
    "    else:\n",
    "        author = author.capitalize()\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_from_text(text, regex, flags):\n",
    "    if flags == True:\n",
    "        text = re.sub(regex, '', text, flags=re.IGNORECASE)\n",
    "    else:\n",
    "        text = re.sub(regex, '', text)        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_place(text, cities_reg):\n",
    "    if len(text.split()) > 0:\n",
    "        removed_part = remove_word_from_text(' '.join(text.split()[:2]), cities_reg, True)\n",
    "        text = removed_part + ' ' + ' '.join(text.split()[2:])\n",
    "    if '-' in \"\".join(text.split()[:5]):\n",
    "        text = text.split('-', 1)[1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_words(regular_df, authors):\n",
    "    vervolg = \"(vervolg van vervolg van pagina\\s\\d{1,2})|(vervolg van pagina\\s\\d{1,2})|(vervolg vanpagina\\s\\d{1,2})|(vervolg van pagina\\s\\d{1,2}-)|(vervolg van voorpagina)|(vervolg van pagina)\"\n",
    "    city_list = pd.read_csv('data/Woonplaatsen_in_Nederland_2020_20122021_042012.csv', sep=';')['Woonplaatsen'].tolist()\n",
    "    # Regex for authors\n",
    "    authors_reg = '|'.join(authors)\n",
    "    door_authors_reg = \"(door) \" + \"(\" + authors_reg + \")\"\n",
    "    door_authors_extra_reg =  \"(\" + authors_reg + \")\" + '|' + \"(\" + door_authors_reg + \")\" \n",
    "    cities_reg = '|'.join(city_list) # removed Ee and EEN which are places\n",
    "\n",
    "    # Remove leading and trailing whitespaces\n",
    "    regular_df['preprocessed_hlead'] = regular_df.Hlead.apply(lambda x: \" \".join(x.split()))\n",
    "    \n",
    "     # Remove 'vervolg van pagina x'\n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: remove_word_from_text(x, vervolg, True)) \n",
    "    \n",
    "    print(\"Vervolgpagina's removed\")\n",
    "    \n",
    "    # Find new author\n",
    "    regular_df['Nieuwe auteur'] = regular_df.apply(lambda x: find_author(x.preprocessed_hlead, x.Auteur, door_authors_extra_reg), axis=1)   \n",
    "    \n",
    "    print(\"New authors found\")\n",
    "    \n",
    "    # Remove 'Authors/door Author/door Author-'\n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: remove_word_from_text(x, door_authors_extra_reg, True))   \n",
    "\n",
    "    # Remove leading and trailing whitespaces\n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: \" \".join(x.split()))   \n",
    "    \n",
    "    print(\"Authors removed from text\")\n",
    "    \n",
    "    # Remove first -\n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: x[1:] if x[0]=='-' else x)   \n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: \" \".join(x.split()))  \n",
    "    \n",
    "    # Remove place name \n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: remove_place(x, cities_reg))  \n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    regular_df['preprocessed_hlead'] = regular_df.preprocessed_hlead.apply(lambda x: \" \".join(x.split()))  \n",
    "    print(\"Placenames removed\")\n",
    "\n",
    "    return regular_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors = get_unique_authors(regular_base_df)\n",
    "# regular_df_cleaned = remove_extra_words(regular_base_df, authors)\n",
    "# regular_df_cleaned.to_csv('complete-clean-preprocessed-data-2010-2020.tsv', sep='\\t', index=False)\n",
    "regular_df_cleaned = pd.read_csv('data/complete-clean-preprocessed-data-2010-2020.tsv', sep='\\t')\n",
    "print(regular_df_cleaned.isna().mean().round(4) * 100)\n",
    "\n",
    "print(regular_df_cleaned['Auteur'].value_counts())\n",
    "print(regular_df_cleaned['Nieuwe auteur'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "top_new_auteurs = regular_df_cleaned['Nieuwe auteur'].value_counts().head(10)\n",
    "ta = top_new_auteurs.plot(kind='bar')\n",
    "ta.axhline(np.array(top_new_auteurs.values).mean(), color='r', linestyle='--', lw=1, label='mean count')\n",
    "plt.xlabel('authors')\n",
    "plt.ylabel('number of articles')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(bc_path + 'top-new-auteurs', bbox_inches = 'tight')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
